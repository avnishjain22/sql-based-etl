apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  # only need if using Argo console or CLI
  generateName: scd2-job-
  namespace: spark
  ## only need if use kubectl
  # name: scd2-job
spec:
  serviceAccountName: arcjob
  entrypoint: scd2-process
  templates:
  - name: scd2-process
    dag:
      tasks:
        - name: initial-load
          templateRef:
            name: spark-template
            template: smallJob
            clusterScope: true 
          arguments:
            parameters:
            - name: jobId
              value: initial-load
            - name: image
              value: ghcr.io/tripl-ai/arc:arc_3.7.0_spark_3.0.1_scala_2.12_hadoop_3.2.0_1.4.0
            - name: configUri
              value: "s3a://{{codeBucket}}/app_code/job/initial_load.ipynb"
            - name: parameters
              value: "--ETL_CONF_DATALAKE_LOC={{codeBucket}}"
        - name: delta-load
          templateRef:
            name: spark-template
            template: smallJob
            clusterScope: true 
          arguments:
            parameters:
            - name: jobId
              value: delta-load 
            - name: image
              value: ghcr.io/tripl-ai/arc:arc_3.7.0_spark_3.0.1_scala_2.12_hadoop_3.2.0_1.4.0
            - name: configUri
              value: "s3a://{{codeBucket}}/app_code/job/delta_load.ipynb"
            - name: parameters
              value: "--ETL_CONF_DATALAKE_LOC={{codeBucket}}"  
        - name: SCD2-merge
          dependencies: [initial-load, delta-load]
          templateRef:
            name: spark-template
            template: smallJob
            clusterScope: true 
          arguments:
            parameters:
            - name: jobId
              value: SCD2-merge 
            - name: image
              value: ghcr.io/tripl-ai/arc:arc_3.7.0_spark_3.0.1_scala_2.12_hadoop_3.2.0_1.4.0
            - name: configUri
              value: "s3a://{{codeBucket}}/app_code/job/SCD2_merge.ipynb"
            - name: parameters
              value: "--ETL_CONF_DATALAKE_LOC={{codeBucket}}"           
            - name: sparkConf
              value: "--conf spark.databricks.delta.merge.repartitionBeforeWrite.enabled=true" 
