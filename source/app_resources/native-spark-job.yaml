apiVersion: batch/v1
kind: Job
metadata:
  name: word-count
  namespace: spark
spec:
  template:
    spec:
      serviceAccountName: nativejob
      restartPolicy: Never 
      containers:
      - name: word-count
        image: {{ACCOUNTNUMBER}}.dkr.ecr.{{REGION}}.amazonaws.com/arc:latest
        command: [
        "/bin/sh",
        "-c",
        "/opt/spark/bin/spark-submit \
        --master k8s://kubernetes.default.svc:443 \
        --deploy-mode cluster \
        --name 'Word Count' \  
        --conf spark.executor.instances=5 \
        --conf spark.kubernetes.allocation.batch.size=10 \ 
        --conf spark.kubernetes.driver.request.cores=2 \
        --conf spark.kubernetes.driver.limit.cores=3 \
        --conf spark.executor.memory=10g \
        --conf spark.kubernetes.executor.request.cores=2 \
        --conf spark.kubernetes.executor.limit.cores=3 \
        --conf spark.kubernetes.container.image={{ACCOUNTNUMBER}}.dkr.ecr.{{REGION}}.amazonaws.com/arc:latest \
        --conf spark.kubernetes.container.image.pullPolicy=Always \
        --conf spark.kubernetes.authenticate.driver.serviceAccountName=nativejob \
        --conf spark.kubernetes.namespace=spark \
        --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
        --conf spark.hadoop.fs.s3a.fast.upload=true \
        --conf spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.WebIdentityTokenCredentialsProvider \
        --conf spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a=org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory \
        --conf spark.hadoop.fs.s3a.committer.name=directory \
        --conf spark.hadoop.fs.s3a.committer.staging.conflict-mode=append \
        --conf spark.kubernetes.driver.podTemplateFile='driver-pod-template.yaml' \
        --conf spark.kubernetes.executor.podTemplateFile='executor-pod-template.yaml' \
        \"s3a://{{codeBucket}}/app_code/job/wordcount.py\" \
        \"s3a://{{codeBucket}}/app_code/output/native\""
        ]
