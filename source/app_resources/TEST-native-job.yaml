apiVersion: batch/v1
kind: Job
metadata:
  name: k8s-job
  namespace: spark
spec:
  template:
    spec:
      serviceAccountName: nativejob
      restartPolicy: Never 
      containers:
      - name: word-count
        image: {{ACCOUNTNUMBER}}.dkr.ecr.{{REGION}}.amazonaws.com/arc:latest
        command: [
        "/bin/sh",
        "-c",
        "/opt/spark/bin/spark-submit \
        --master k8s://kubernetes.default.svc:443 \
        --deploy-mode cluster \
        --name 'Word Count' \  
        --conf spark.executor.instances=5 \
        --conf spark.kubernetes.allocation.batch.size=10 \ 
        --conf spark.kubernetes.driver.request.cores=2 \
        --conf spark.kubernetes.driver.limit.cores=3 \
        --conf spark.executor.memory=10g \
        --conf spark.kubernetes.executor.request.cores=2 \
        --conf spark.kubernetes.executor.limit.cores=3 \
        --conf spark.kubernetes.container.image={{ACCOUNTNUMBER}}.dkr.ecr.{{REGION}}.amazonaws.com/arc:latest \
        --conf spark.kubernetes.container.image.pullPolicy=Always \
        --conf spark.kubernetes.driver.podTemplateFile='driver-pod-template.yaml' \
        --conf spark.kubernetes.executor.podTemplateFile='executor-pod-template.yaml' \
        --conf spark.kubernetes.authenticate.driver.serviceAccountName=nativejob \
        --conf spark.kubernetes.namespace=spark \
        --conf spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \
        --conf spark.hadoop.fs.s3a.fast.upload=true \
        --conf spark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.WebIdentityTokenCredentialsProvider \
        wordcount.py \
        \"s3a://{{CODE_BUCKET}}/app_code/output\""
        ]
